Fig 1. A teaser of this paper with six images with labels a), b), c), d), e) f) in two rows. The first row with three images depicts a scenario of a girl creating with Neural Canvas. The second row shows the process of integrating AI functions to convert an AI-generated image to a 3D scene. Image a) is a photo showing a girl designing a scene with a digital plate at a computer. Image b) shows the demo of the girl's design, which is a scene of the Underwater World full of ocean animals. Image c) is another rendering from a different view angle of the girl's design, showcasing the three-dimensional nature of the design. Image d) is a screenshot of a designed scene of Neural Canvas, where simple 3D primitives are placed with different colors. Image e) is an anime-style rendering of Image d) with the same layout and structure. There are two buildings on either side of the picture, with a road leading to the sea in the middle and a magnificent castle in the distance on the sea. Image f) contains four small images, showing the 3D scene converted from Image e) from 4 different view angles.


Fig 2. Line graph showing information capacities of different expression forms on the Y axis against expression difficulties on the X axis. There is a curve in the shape of a log function with 4 points indicating text, sketch, image, and 3d model. The figure illustrates that the more information capacity an expression form has, the more difficult to create. There are another two points on the right-up side of points of text and sketch, showing the expansion of information capacities with little effort. They are AI-generated content and 3D sketch. Another point with a caption of Neural Canvsas has two dot lines pointing to it, which means integration of AI-generated content and 3D sketch.


Fig 3. System architecture with 3 layers: user, front-end client, and backend services. Users give input to the front-end client and get back visual results from the 3D renderer of the front-end client. The front-end client consists of an editor module, an AI module, a camera module, simple image editing functions, and a 3D renderer. The information processed by the client is then fed to back-end services. The back-end services are divided into three parts: a web server, self-hosted services, and services provided by
cloud or SaaS companies.


Fig 4. User interface with a similar layout to Photoshop. There is a toolbar on the left side and a panel on the right side, with a canvas in the middle showing the 3D scene. There are 5 subfigures showing the corresponding function tab of the right panel: color manager, layer manager, camera manager, 3D primitive manager, and environment manager.


Fig 5. Four images illustrating the process of converting an image into a 3D scene. The first image shows a man standing on a cliff with his dog and looking at remote mountains. The second image shows the same visual content as the first image but in a 3D way. The third image is rendered from another view angle and the background of mountains has a white hole with the shape of the man. And the last image shows the same 3D scene without blank holes.


Fig 6. User interface of the AI module with nine tabs on the left-side toolbar. Two images in the body show the current scene preview or design, and AI-generated content respectively.


Fig 7. Three images in the forms of coarse sketch, photorealistic image, and fine-grained sketch. Three images depict the same alley in different ways. Two buildings are arranged on both sides of the images, and there is a path in the middle leading to the depths of the alley.


Fig 8. Six derivative images of the same poster of a game, The Legend of Zelda: Breath of the Wild. The first picture is the original picture, a man with his back to the reader, looking into the distance under the vast sky. The second one is a white-black image indicating the estimated depth information of each pixel. The third and fourth ones are the split foreground and background. The fifth image is about the background without white holes. And the last image shows the background with a wider field of view.


Fig 9. Four design demos created on Neural Canvas. The first demo is a scene of an ancient mausoleum with assets in traditional Chinese style. The second one consists of four views of a scene created by 3D sketches. Three images of different styles with the same content are derived from the third demo about a game scenario. Then two images of the fourth demo are followed. They are an engineering sketch of the gymnasium made in advance with other CAD software and a rendering from Neural Canvas.


Fig 10. Histogram of rating results about the overall user experience of the system. Users gave their ratings on nine pre-defined statements about our Neural Canvas to show their agreement degree. Each bar is with the same width and is divided into blocks with different widths and colors where the widths show the number of participants and the colors show the corresponding score. Among more than 100 ratings, there are only a few ratings below 4.


Fig 11. Histogram of rating results about the user experience of respective system features. Users gave their ratings on 11 different features of Neural Canvas. Each bar indicates the results of a function. Different bars have different lengths since some users didn't use all the functions. Each bar is divided into blocks with different widths and colors where the widths show the number of participants and the colors show the corresponding score. Of the 11 features reviewed, there are only 8 ratings in a total of more than 100 below 4 out of 7.